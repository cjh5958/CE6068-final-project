# ğŸ§¬ ç™½è¡€ç—…åŸºå› è¡¨é”è³‡æ–™å¢å¼·æœ€ä½³å¯¦è¸æŒ‡å—

## å°ˆæ¡ˆç›®æ¨™
æœ¬å°ˆæ¡ˆé‡å°æ¥µé«˜ç¶­ï¼ˆ22,283ç¶­ï¼‰å°æ¨£æœ¬ï¼ˆ64ç­†ï¼‰ç™½è¡€ç—…åŸºå› è¡¨é”è³‡æ–™ï¼Œå»ºç«‹ç©©å®šå¯è¤‡ç¾çš„è³‡æ–™å¢å¼·èˆ‡ä¸‹æ¸¸åˆ†ææµç¨‹ã€‚æ ¸å¿ƒç­–ç•¥ç‚ºï¼š
- å…ˆç”¨PCAé™ç¶­ï¼ˆå»ºè­°32ç¶­ï¼Œå‹¿è¶…éæ¨£æœ¬æ•¸ï¼‰
- å†ä»¥æ¢ä»¶è®Šåˆ†è‡ªç·¨ç¢¼å™¨ï¼ˆcVAEï¼‰é€²è¡Œè³‡æ–™ç”Ÿæˆ
- æ‰€æœ‰ä¸‹æ¸¸æµç¨‹ï¼ˆåˆ†é¡ã€åˆ†æï¼‰çš†ç›´æ¥ç”¨é™ç¶­å¾Œè³‡æ–™ï¼Œä¸é‚„åŸé«˜ç¶­
- å…¨æµç¨‹è³‡æ–™æ¬„ä½ã€æ¨¡å‹çµæ§‹éœ€å®Œå…¨ä¸€è‡´

## é‡ç¾æœ€ä½³å¯¦è¸çš„å®Œæ•´æ­¥é©Ÿ

### 1. æº–å‚™åŸå§‹è³‡æ–™
- å°‡åŸå§‹ 64Ã—22,283 ç¶­è³‡æ–™æ”¾æ–¼ `datasets/raw_data.csv`

### 2. PCAé™ç¶­èˆ‡å‰è™•ç†
```bash
python train_model.py --pca-dim 32
```
- ç”¢ç”Ÿ `datasets/raw_data_reduced.csv`ï¼Œæ¬„ä½ç‚ºï¼šsamples, type, PCA_0, ..., PCA_31
- **æ³¨æ„ï¼šPCAç¶­åº¦ä¸å¯è¶…éæ¨£æœ¬æ•¸**

### 3. cVAEè¨“ç·´
- åŒä¸ŠæŒ‡ä»¤ï¼Œæ¨¡å‹è‡ªå‹•ä»¥é™ç¶­å¾Œè³‡æ–™è¨“ç·´
- æ¨è–¦æ¨¡å‹çµæ§‹ï¼š
  - input_dim=32
  - encoder_hidden_dims=[64,32]
  - decoder_hidden_dims=[32,64]
  - latent_dim=16
- è«‹æ–¼configæˆ–æŒ‡ä»¤æ˜ç¢ºæŒ‡å®šï¼Œå‹¿è‡ªå‹•æ¨æ–·

### 4. ç”Ÿæˆè³‡æ–™
```bash
python generate_data.py --samples 100
```
- ç”¢ç”Ÿ `datasets/gen_data.csv`ï¼Œæ¬„ä½èˆ‡ `raw_data_reduced.csv` å®Œå…¨ä¸€è‡´
- **ç”Ÿæˆè³‡æ–™ä¸éœ€é‚„åŸé«˜ç¶­ï¼Œç›´æ¥ç”¨é™ç¶­æ ¼å¼**

### 5. ä¸‹æ¸¸åˆ†é¡/åˆ†æ
- åˆä½µ `raw_data_reduced.csv` èˆ‡ `gen_data.csv`ï¼Œæ–¼ `base_model.py` é€²è¡Œåˆ†é¡è¨“ç·´èˆ‡è©•ä¼°
- å¯ç”¨ `analyze_dataset.py` é€²è¡Œå“è³ªåˆ†æ

## æŒ‡ä»¤ç¯„ä¾‹

#### è¨“ç·´ï¼ˆå«PCAé™ç¶­ï¼‰
```bash
python train_model.py --pca-dim 32 --epochs 100 --batch-size 8 --latent-dim 16 --encoder-hidden-dims 64 32 --decoder-hidden-dims 32 64
```

#### ç”Ÿæˆè³‡æ–™
```bash
python generate_data.py --samples 100
```

#### ä¸‹æ¸¸åˆ†æ
```bash
python analyze_dataset.py datasets/gen_data.csv
```

## è³‡æ–™æ ¼å¼èªªæ˜
- **é™ç¶­å¾Œè³‡æ–™/ç”Ÿæˆè³‡æ–™**ï¼š
  - æ¬„ä½ï¼šsamples, type, PCA_0, ..., PCA_31
  - å…©è€…æ¬„ä½ã€é †åºã€ç¶­åº¦å®Œå…¨ä¸€è‡´
- **ç›´æ¥åˆä½µç”¨æ–¼ä¸‹æ¸¸åˆ†é¡èˆ‡åˆ†æ**
- **ä¸éœ€é‚„åŸåˆ°åŸå§‹22,283ç¶­**

## å¸¸è¦‹å•é¡Œèˆ‡æ’é™¤

- **PCAç¶­åº¦è¶…éæ¨£æœ¬æ•¸**ï¼šè«‹å°‡ `--pca-dim` è¨­ç‚ºå°æ–¼ç­‰æ–¼æ¨£æœ¬æ•¸
- **LabelEncoderéŒ¯èª¤**ï¼šè«‹å…ˆfitå…¨é«”yå†åˆ†å‰²è³‡æ–™
- **è³‡æ–™shapeä¸ç¬¦/æ¨¡å‹çµæ§‹ä¸ä¸€è‡´**ï¼šè¨“ç·´èˆ‡ç”Ÿæˆæµç¨‹input_dimã€hidden_dimsã€latent_diméœ€å®Œå…¨ä¸€è‡´
- **ç”Ÿæˆè³‡æ–™æ¬„ä½ä¸ç¬¦**ï¼šè«‹ç¢ºèªç”Ÿæˆè³‡æ–™èˆ‡é™ç¶­è³‡æ–™æ¬„ä½ã€é †åºä¸€è‡´
- **æ¨¡å‹æª”æœªæ­£ç¢ºè¦†è“‹**ï¼šè«‹æª¢æŸ¥ `models/` ç›®éŒ„ä¸‹æª”æ¡ˆ

## æŠ€è¡“ç´°ç¯€
- **PCAé™ç¶­**ï¼šfitæ–¼è¨“ç·´é›†ï¼Œtransformæ–¼æ¸¬è©¦/ç”Ÿæˆ
- **cVAEæ¨¡å‹**ï¼šæ¢ä»¶ç¶­åº¦=5ï¼ˆäº”ç¨®ç™½è¡€ç—…é¡å‹ï¼‰ï¼Œæ¨è–¦çµæ§‹å¦‚ä¸Š
- **è³‡æ–™åˆ†å‰²**ï¼šè¨“ç·´/é©—è­‰/æ¸¬è©¦ = 73%/12%/15%
- **ä¸‹æ¸¸åˆ†é¡**ï¼šç›´æ¥ç”¨é™ç¶­å¾Œè³‡æ–™é€²è¡Œ

## é‡è¦æé†’
- **å…¨æµç¨‹è³‡æ–™æ ¼å¼ã€æ¨¡å‹çµæ§‹éœ€ä¸€è‡´**ï¼Œé¿å…ä»»ä½•è‡ªå‹•æ¨æ–·
- **ç”Ÿæˆè³‡æ–™ç›´æ¥ç”¨æ–¼ä¸‹æ¸¸ï¼Œä¸éœ€é‚„åŸé«˜ç¶­**
- **å¦‚é‡bugï¼Œè«‹å…ˆæª¢æŸ¥è³‡æ–™shapeã€æ¬„ä½ã€æ¨¡å‹çµæ§‹ä¸€è‡´æ€§**

## ğŸ“‹ å°ˆæ¡ˆæ¦‚è¿°

æœ¬å°ˆæ¡ˆæä¾›å®Œæ•´çš„æ¢ä»¶è®Šåˆ†è‡ªç·¨ç¢¼å™¨ (Conditional VAE, cVAE) è§£æ±ºæ–¹æ¡ˆï¼Œç”¨æ–¼ç™½è¡€ç—…åŸºå› è¡¨é”è³‡æ–™çš„è¨“ç·´å’Œç”Ÿæˆã€‚æ”¯æ´å¾é›¶é–‹å§‹è¨“ç·´æ¨¡å‹ï¼Œä»¥åŠä½¿ç”¨é è¨“ç·´æ¨¡å‹ç”Ÿæˆé«˜å“è³ªåˆæˆè³‡æ–™ã€‚

### ğŸ¯ ä¸»è¦åŠŸèƒ½
- **æ¨¡å‹è¨“ç·´**: å®Œæ•´çš„ cVAE è¨“ç·´æµç¨‹ï¼Œæ”¯æ´è‡ªè¨‚åƒæ•¸
- **è³‡æ–™ç”Ÿæˆ**: ä½¿ç”¨é è¨“ç·´æ¨¡å‹ç”Ÿæˆåˆæˆè³‡æ–™
- **å¤šé¡å‹æ”¯æ´**: æ”¯æ´ 5 ç¨®ç™½è¡€ç—…é¡å‹çš„è³‡æ–™ç”Ÿæˆ
- **æ ¼å¼å…¼å®¹**: ç”Ÿæˆè³‡æ–™å®Œå…¨åŒ¹é…åŸå§‹è³‡æ–™æ ¼å¼ï¼Œä¾¿æ–¼ä¸‹æ¸¸ä½¿ç”¨
- **éˆæ´»è¼¸å‡º**: æ”¯æ´ CSV å’Œ PKL æ ¼å¼
- **ğŸ†• è¦–è¦ºåŒ–åˆ†æ**: è‡ªå‹•ç”Ÿæˆè³‡æ–™åˆ†å¸ƒæª¢å®šåœ–è¡¨
- **ğŸ†• å“è³ªç›£æ§**: PCAã€t-SNEã€ç›¸é—œæ€§åˆ†æç­‰å¤šç¶­åº¦è©•ä¼°
- **ğŸ†• æ·±åº¦åˆ†æ**: å°ˆæ¥­çš„è³‡æ–™é›†åˆ†æå·¥å…·ï¼Œæ”¯æ´ PCAã€t-SNEã€UMAP ç­‰å¤šç¨®é™ç¶­æ–¹æ³•

### ğŸ§ª æ”¯æ´çš„ç™½è¡€ç—…é¡å‹
1. **AML** - æ€¥æ€§éª¨é«“æ€§ç™½è¡€ç—…
2. **Bone_Marrow** - éª¨é«“æ¨£æœ¬
3. **Bone_Marrow_CD34** - CD34+ éª¨é«“ç´°èƒ
4. **PB** - å‘¨é‚Šè¡€æ¶²
5. **PBSC_CD34** - CD34+ å‘¨é‚Šè¡€æ¶²å¹¹ç´°èƒ

## ğŸ“ å°ˆæ¡ˆçµæ§‹

```
CE6068-final-project/
â”œâ”€â”€ README.md                    # æœ¬æª”æ¡ˆ
â”œâ”€â”€ train_model.py               # æ¨¡å‹è¨“ç·´è…³æœ¬
â”œâ”€â”€ generate_data.py             # è³‡æ–™ç”Ÿæˆè…³æœ¬ (å«è¦–è¦ºåŒ–åˆ†æ)
â”œâ”€â”€ analyze_dataset.py           # ğŸ†• å°ˆæ¥­è³‡æ–™é›†åˆ†æå·¥å…·
â”œâ”€â”€ model_usage_guide.py         # Python API ä»‹é¢
â”œâ”€â”€ models/                      # è¨“ç·´å¥½çš„æ¨¡å‹
â”‚   â”œâ”€â”€ leukemia_cvae_model.pth  # ä¸»è¦ cVAE æ¨¡å‹æª”æ¡ˆ
â”‚   â”œâ”€â”€ best_cvae_model.pth      # æœ€ä½³é©—è­‰æ¨¡å‹
â”‚   â””â”€â”€ final_cvae_model.pth     # æœ€çµ‚è¨“ç·´æ¨¡å‹
â”œâ”€â”€ datasets/                    # è³‡æ–™æª”æ¡ˆ
â”‚   â”œâ”€â”€ raw_data.csv            # åŸå§‹è³‡æ–™é›†
â”‚   â”œâ”€â”€ scaler.pkl              # ç‰¹å¾µæ­£è¦åŒ–å™¨
â”‚   â”œâ”€â”€ label_encoder.pkl       # æ¨™ç±¤ç·¨ç¢¼å™¨
â”‚   â”œâ”€â”€ metadata.pkl            # è³‡æ–™å…ƒè³‡è¨Š (å«åŸºå› åç¨±)
â”‚   â”œâ”€â”€ generated_data_*.csv    # ğŸ†• ç”Ÿæˆçš„è³‡æ–™æª”æ¡ˆ
â”‚   â””â”€â”€ plots/                  # ğŸ†• åˆ†å¸ƒæª¢å®šåœ–è¡¨ç›®éŒ„
â”‚       â”œâ”€â”€ *_class_distribution.png     # é¡åˆ¥åˆ†å¸ƒåœ–
â”‚       â”œâ”€â”€ *_statistics_summary.png     # çµ±è¨ˆæ‘˜è¦åœ–
â”‚       â”œâ”€â”€ *_pca_analysis.png           # PCA åˆ†æåœ–
â”‚       â”œâ”€â”€ *_tsne_analysis.png          # t-SNE åˆ†æåœ–
â”‚       â”œâ”€â”€ *_umap_analysis.png          # ğŸ†• UMAP åˆ†æåœ–
â”‚       â”œâ”€â”€ *_correlation_analysis.png   # ç›¸é—œæ€§åˆ†æåœ–
â”‚       â””â”€â”€ [è³‡æ–™é›†åç¨±]_analysis/        # ğŸ†• å®Œæ•´åˆ†æçµæœç›®éŒ„
â”œâ”€â”€ training_logs/              # è¨“ç·´æ—¥èªŒ (è¨“ç·´å¾Œç”¢ç”Ÿ)
â””â”€â”€ [æ ¸å¿ƒç¨‹å¼ç¢¼æª”æ¡ˆ]
```

## ğŸš€ å¿«é€Ÿé–‹å§‹

### **ç’°å¢ƒè¨­ç½®**
```bash
# å»ºç«‹ä¸¦å•Ÿå‹•è™›æ“¬ç’°å¢ƒ (å»ºè­°)
python -m venv venv
# Windows
venv\Scripts\activate
# Linux/Mac
source venv/bin/activate

# å®‰è£ä¾è³´
pip install -r requirements.txt
```

### **æ–¹å¼ 1: æ¨¡å‹è¨“ç·´ (å¾é›¶é–‹å§‹)**

```bash
# åŸºæœ¬è¨“ç·´ (ä½¿ç”¨é è¨­åƒæ•¸)
python train_model.py

# å¿«é€Ÿè¨“ç·´ (è¼ƒå°‘epochsï¼Œé©åˆæ¸¬è©¦)
python train_model.py --epochs 10 --batch-size 4

# è‡ªè¨‚è¨“ç·´åƒæ•¸
python train_model.py --epochs 150 --batch-size 16 --learning-rate 5e-5

# ä½¿ç”¨GPUè¨“ç·´ (å¦‚æœå¯ç”¨)
python train_model.py --device cuda

# ä½¿ç”¨é…ç½®æª”æ¡ˆ
python train_model.py --config my_config.json
```

### **æ–¹å¼ 2: è³‡æ–™ç”Ÿæˆ (ä½¿ç”¨é è¨“ç·´æ¨¡å‹) ğŸ†•**

```bash
# ç”Ÿæˆå¹³è¡¡è³‡æ–™é›† (æ¨è–¦) - å«å®Œæ•´è¦–è¦ºåŒ–åˆ†æ
python generate_data.py --balanced --samples-per-class 50

# ç”Ÿæˆç‰¹å®šé¡å‹æ¨£æœ¬ - å«åˆ†å¸ƒæª¢å®šåœ–è¡¨
python generate_data.py --type AML --samples 100

# è‡ªè¨‚è¼¸å‡ºæª”åå’Œæ ¼å¼
python generate_data.py --type PB --samples 200 --format csv --output my_leukemia_data

# è·³éåœ–è¡¨ç”Ÿæˆ (ç´”è³‡æ–™ç”Ÿæˆ)
python generate_data.py --balanced --samples-per-class 30 --no-plots
```

### **æ–¹å¼ 3: ğŸ†• è³‡æ–™é›†æ·±åº¦åˆ†æ**

```bash
# å®Œæ•´åˆ†æ - PCAã€t-SNEã€UMAPã€ç›¸é—œæ€§ã€çµ±è¨ˆç‰¹æ€§
python analyze_dataset.py datasets/generated_data_20250602_201358.csv

# å¿«é€Ÿåˆ†æ (é™åˆ¶ç›¸é—œæ€§åˆ†æç‰¹å¾µæ•¸)
python analyze_dataset.py datasets/my_data.csv --max-corr-features 50

# è·³éè¨ˆç®—å¯†é›†çš„åˆ†æ
python analyze_dataset.py datasets/large_data.csv --skip-tsne --skip-correlation

# åˆ†æåŸå§‹è³‡æ–™é€²è¡Œæ¯”è¼ƒ
python analyze_dataset.py datasets/raw_data.csv
```

### **æ–¹å¼ 4: Python API**

```python
from model_usage_guide import LeukemiaCVAEGenerator

# åˆå§‹åŒ–ç”Ÿæˆå™¨
generator = LeukemiaCVAEGenerator()

# ç”Ÿæˆç‰¹å®šé¡å‹æ¨£æœ¬
aml_data = generator.quick_generate_and_save(
    leukemia_type='AML', 
    n_samples=100,
    save_format='both'
)

# ç”Ÿæˆå¹³è¡¡è³‡æ–™é›†
balanced_data = generator.quick_generate_balanced_and_save(
    samples_per_class=50,
    save_format='both'
)
```

## ğŸ“Š ğŸ†• å°ˆæ¥­è³‡æ–™åˆ†æåŠŸèƒ½

### **analyze_dataset.py åŠŸèƒ½æ¦‚è¦½**

æ–°å¢çš„å°ˆæ¥­åˆ†æå·¥å…·æä¾›å¤šç¶­åº¦çš„è³‡æ–™å“è³ªæª¢æ¸¬ï¼š

- **ğŸ” PCA ä¸»æˆåˆ†åˆ†æ**: é™ç¶­ã€è®Šç•°è§£é‡‹ã€é¡åˆ¥åˆ†é›¢åº¦è©•ä¼°
- **ğŸŒ€ t-SNE éç·šæ€§é™ç¶­**: æ¢ç´¢éç·šæ€§èšé›†çµæ§‹  
- **ğŸ—ºï¸ UMAP çµ±ä¸€æµå½¢é€¼è¿‘**: å¹³è¡¡å±€éƒ¨èˆ‡å…¨å±€çµæ§‹çš„ç¾ä»£é™ç¶­æ–¹æ³•
- **ğŸ”— ç›¸é—œæ€§åˆ†æ**: ç‰¹å¾µé–“ç›¸é—œæ€§ç†±åŠ›åœ–å’Œçµ±è¨ˆæ‘˜è¦
- **ğŸ“ˆ çµ±è¨ˆç‰¹æ€§åˆ†æ**: é¡åˆ¥åˆ†å¸ƒã€ç‰¹å¾µåˆ†å¸ƒã€å“è³ªè©•ä¼°
- **ğŸ“Š é™ç¶­æ–¹æ³•æ¯”è¼ƒ**: ä¸¦æ’æ¯”è¼ƒä¸åŒé™ç¶­æŠ€è¡“çš„æ•ˆæœ

### **åˆ†æè¼¸å‡ºçµæ§‹**
```
datasets/plots/
â””â”€â”€ [è³‡æ–™é›†åç¨±]_analysis/
    â”œâ”€â”€ pca_analysis.png              # PCA ä¸»æˆåˆ†åˆ†æåœ–
    â”œâ”€â”€ tsne_analysis.png             # t-SNE é™ç¶­åˆ†æåœ–
    â”œâ”€â”€ umap_analysis.png             # UMAP é™ç¶­åˆ†æåœ–
    â”œâ”€â”€ correlation_analysis.png      # ç‰¹å¾µç›¸é—œæ€§åˆ†æåœ–
    â”œâ”€â”€ statistical_analysis.png      # çµ±è¨ˆç‰¹æ€§åˆ†æåœ–
    â””â”€â”€ dimensionality_reduction_comparison.png  # é™ç¶­æ–¹æ³•æ¯”è¼ƒåœ–
```

### **å¸¸ç”¨åˆ†ææŒ‡ä»¤**
```bash
# 1. åŸºæœ¬å®Œæ•´åˆ†æ
python analyze_dataset.py datasets/generated_data.csv

# 2. æ•ˆèƒ½å„ªåŒ–åˆ†æ (æ¨è–¦ç”¨æ–¼å¤§å‹è³‡æ–™é›†)
python analyze_dataset.py datasets/large_data.csv --max-corr-features 50

# 3. æ¯”è¼ƒåŸå§‹ vs ç”Ÿæˆè³‡æ–™
python analyze_dataset.py datasets/raw_data.csv --output-dir comparison
python analyze_dataset.py datasets/generated_data.csv --output-dir comparison

# 4. è¼•é‡ç´šåˆ†æ (è·³éè¨ˆç®—å¯†é›†é …ç›®)
python analyze_dataset.py datasets/data.csv --skip-tsne --skip-correlation
```

## ğŸ“Š è©³ç´°è³‡æ–™åˆ†æå·¥å…·ä½¿ç”¨æŒ‡å—

### **ğŸ¨ åˆ†æåœ–è¡¨è©³è§£**

#### **1. PCA ä¸»æˆåˆ†åˆ†æ (`pca_analysis.png`)**
- **2D æ•£é»åœ–**ï¼šå„é¡åˆ¥åœ¨å‰å…©å€‹ä¸»æˆåˆ†ç©ºé–“çš„åˆ†å¸ƒ
- **è®Šç•°è§£é‡‹æ¯”ä¾‹**ï¼šå„ä¸»æˆåˆ†çš„è²¢ç»åº¦æŸ±ç‹€åœ–
- **ç´¯ç©è®Šç•°æ›²ç·š**ï¼šä¸»æˆåˆ†ç´¯ç©è§£é‡‹è®Šç•°è¶¨å‹¢
- **å“è³ªè©•ä¼°**ï¼šSilhouette Score å’Œé—œéµçµ±è¨ˆæŒ‡æ¨™

#### **2. t-SNE éç·šæ€§é™ç¶­ (`tsne_analysis.png`)**
- **2D æŠ•å½±**ï¼šæ¢ç´¢éç·šæ€§èšé›†æ¨¡å¼
- **å“è³ªè©•ä¼°**ï¼šèšé¡åˆ†é›¢åº¦è©•åˆ†
- **è‡ªå‹•æ¡æ¨£**ï¼šå¤§è³‡æ–™é›†è‡ªå‹•æ¡æ¨£ä»¥æå‡è¨ˆç®—æ•ˆç‡

#### **3. UMAP çµ±ä¸€æµå½¢é€¼è¿‘ (`umap_analysis.png`)**
- **2D æŠ•å½±**ï¼šä¿æŒå±€éƒ¨å’Œå…¨å±€çµæ§‹çš„é™ç¶­çµæœ
- **å“è³ªè©•ä¼°**ï¼šèšé¡å“è³ªè©•åˆ†
- **åƒæ•¸å±•ç¤º**ï¼šneighbors åƒæ•¸ç­‰è¨­å®šè³‡è¨Š

#### **4. ç›¸é—œæ€§åˆ†æ (`correlation_analysis.png`)**
- **ç›¸é—œæ€§ç†±åŠ›åœ–**ï¼šé«˜æ–¹å·®ç‰¹å¾µé–“çš„ç›¸é—œæ€§çŸ©é™£
- **ç›¸é—œä¿‚æ•¸åˆ†å¸ƒ**ï¼šæ•´é«”ç›¸é—œæ€§çµ±è¨ˆç›´æ–¹åœ–
- **é«˜ç›¸é—œç‰¹å¾µå°**ï¼šè­˜åˆ¥å†—é¤˜ç‰¹å¾µçš„æ•£é»åœ–
- **çµ±è¨ˆæ‘˜è¦**ï¼šè©³ç´°çš„ç›¸é—œæ€§çµ±è¨ˆå ±å‘Š

#### **5. çµ±è¨ˆç‰¹æ€§åˆ†æ (`statistical_analysis.png`)**
- **é¡åˆ¥åˆ†å¸ƒ**ï¼šå„ç™½è¡€ç—…é¡å‹çš„æ¨£æœ¬åˆ†å¸ƒæŸ±ç‹€åœ–
- **ç‰¹å¾µå¹³å‡å€¼åˆ†å¸ƒ**ï¼šåŸºå› è¡¨é”å¹³å‡å€¼çš„åˆ†å¸ƒç›´æ–¹åœ–
- **ç‰¹å¾µè®Šç•°æ€§**ï¼šåŸºå› è¡¨é”è®Šç•°åº¦çš„åˆ†å¸ƒç›´æ–¹åœ–
- **æ¨£æœ¬é–“è·é›¢**ï¼šæ­å¹¾é‡Œå¾—è·é›¢åˆ†å¸ƒåˆ†æ
- **é¡åˆ¥æ¯”è¼ƒ**ï¼šå„é¡åˆ¥ç‰¹å¾µå€¼çš„ç®±ç·šåœ–æ¯”è¼ƒ
- **å“è³ªæŒ‡æ¨™**ï¼šè³‡æ–™å®Œæ•´æ€§å’Œå¹³è¡¡æ€§è©•ä¼°

#### **6. é™ç¶­æ–¹æ³•æ¯”è¼ƒ (`dimensionality_reduction_comparison.png`)**
- **ä¸¦æ’æ¯”è¼ƒ**ï¼šPCAã€t-SNEã€UMAP çµæœçš„è¦–è¦ºå°æ¯”
- **èšé¡æ•ˆæœ**ï¼šä¸åŒæ–¹æ³•çš„é¡åˆ¥åˆ†é›¢æ•ˆæœ

### **ğŸ¨ ä½¿ç”¨æ¡ˆä¾‹**

#### **æ¡ˆä¾‹ 1: å¿«é€Ÿå“è³ªæª¢æ¸¬**
```bash
# å°æ–°ç”Ÿæˆçš„è³‡æ–™é›†é€²è¡Œå¿«é€Ÿå“è³ªæª¢æ¸¬
python analyze_dataset.py datasets/new_generated_data.csv --max-corr-features 30
```

#### **æ¡ˆä¾‹ 2: è©³ç´°ç ”ç©¶åˆ†æ**
```bash
# å®Œæ•´åˆ†æï¼ŒåŒ…å«æ‰€æœ‰é™ç¶­æ–¹æ³•å’Œè©³ç´°ç›¸é—œæ€§åˆ†æ
python analyze_dataset.py datasets/research_data.csv --max-corr-features 200
```

#### **æ¡ˆä¾‹ 3: è¼•é‡ç´šåˆ†æ**
```bash
# è·³éè¨ˆç®—å¯†é›†çš„åˆ†æï¼Œé©åˆå¤§å‹è³‡æ–™é›†
python analyze_dataset.py datasets/large_dataset.csv --skip-tsne --skip-correlation
```

#### **æ¡ˆä¾‹ 4: æ¯”è¼ƒä¸åŒè³‡æ–™é›†**
```bash
# åˆ†æå¤šå€‹è³‡æ–™é›†ä¸¦æ¯”è¼ƒçµæœ
python analyze_dataset.py datasets/original_data.csv --output-dir comparison_study
python analyze_dataset.py datasets/generated_data.csv --output-dir comparison_study
python analyze_dataset.py datasets/augmented_data.csv --output-dir comparison_study
```

### **ğŸ“ˆ çµæœè§£è®€æŒ‡å—**

#### **PCA åˆ†æè§£è®€**
- **å‰2å€‹ä¸»æˆåˆ†è§£é‡‹è®Šç•° > 50%**ï¼šè³‡æ–™å…·æœ‰è‰¯å¥½çš„ä½ç¶­è¡¨ç¤º
- **å‰2å€‹ä¸»æˆåˆ†è§£é‡‹è®Šç•° < 30%**ï¼šè€ƒæ…®å¢åŠ ä¸»æˆåˆ†æ•¸é‡æˆ–ä½¿ç”¨éç·šæ€§æ–¹æ³•
- **é«˜ Silhouette Score (>0.5)**ï¼šé¡åˆ¥åœ¨é™ç¶­ç©ºé–“ä¸­åˆ†é›¢è‰¯å¥½

#### **t-SNE vs UMAP æ¯”è¼ƒ**
- **t-SNE æ“…é•·**ï¼šç™¼ç¾å±€éƒ¨èšé›†çµæ§‹ï¼Œçªå‡ºé¡åˆ¥å…§çš„ç´°å¾®å·®ç•°
- **UMAP æ“…é•·**ï¼šä¿æŒå…¨å±€çµæ§‹ï¼Œè¨ˆç®—æ•ˆç‡æ›´é«˜ï¼Œåƒæ•¸èª¿æ•´æ›´éˆæ´»
- **å»ºè­°**ï¼šå…©ç¨®æ–¹æ³•çµåˆä½¿ç”¨ï¼Œæä¾›äº’è£œçš„è¦–è§’

#### **ç›¸é—œæ€§åˆ†ææŒ‡å°**
- **é«˜ç›¸é—œç‰¹å¾µå°æ•¸é‡å¤š**ï¼šè€ƒæ…®ç‰¹å¾µé¸æ“‡æˆ–é™ç¶­ä»¥æ¸›å°‘å†—é¤˜
- **å¹³å‡ç›¸é—œä¿‚æ•¸æ¥è¿‘0**ï¼šç‰¹å¾µç¨ç«‹æ€§è‰¯å¥½
- **ç›¸é—œä¿‚æ•¸åˆ†å¸ƒåå‘æ¥µå€¼**ï¼šå¯èƒ½å­˜åœ¨å¼·ç›¸é—œæˆ–å¼·åç›¸é—œçš„åŸºå› ç¾¤çµ„

#### **çµ±è¨ˆç‰¹æ€§è©•ä¼°**
- **é¡åˆ¥å¹³è¡¡åº¦ > 0.8**ï¼šè³‡æ–™é›†å¹³è¡¡æ€§è‰¯å¥½
- **æ¨£æœ¬é–“è·é›¢åˆ†å¸ƒæ­£å¸¸**ï¼šç„¡æ˜é¡¯é›¢ç¾¤å€¼æˆ–æ•¸æ“šå“è³ªå•é¡Œ
- **ç‰¹å¾µè®Šç•°æ€§é©ä¸­**ï¼šåŸºå› è¡¨é”å·®ç•°åˆç†ï¼Œæœ‰åˆ©æ–¼åˆ†é¡

### **ğŸ’¡ æœ€ä½³å¯¦è¸å»ºè­°**

#### **åˆ†æå·¥ä½œæµç¨‹**
1. **åˆæ­¥æª¢æ¸¬**ï¼šä½¿ç”¨é è¨­åƒæ•¸å¿«é€Ÿåˆ†æ
2. **å“è³ªè©•ä¼°**ï¼šæª¢æŸ¥ PCA è§£é‡‹è®Šç•°å’Œ Silhouette Score
3. **æ·±å…¥åˆ†æ**ï¼šæ ¹æ“šåˆæ­¥çµæœèª¿æ•´åƒæ•¸é€²è¡Œè©³ç´°åˆ†æ
4. **æ¯”è¼ƒç ”ç©¶**ï¼šå°æ¯”ä¸åŒè³‡æ–™é›†çš„åˆ†æçµæœ

#### **æ•ˆèƒ½å„ªåŒ–**
- **å¤§å‹è³‡æ–™é›†**ï¼šä½¿ç”¨ `--max-corr-features 50` é™åˆ¶ç›¸é—œæ€§åˆ†æç¯„åœ
- **å¿«é€Ÿæª¢æ¸¬**ï¼šè·³ééå¿…è¦åˆ†æ `--skip-tsne --skip-correlation`
- **æ‰¹æ¬¡è™•ç†**ï¼šç·¨å¯«è…³æœ¬å°å¤šå€‹è³‡æ–™é›†æ‰¹æ¬¡åˆ†æ

#### **çµæœæ‡‰ç”¨**
- **æ¨¡å‹é¸æ“‡**ï¼šæ ¹æ“šé™ç¶­çµæœé¸æ“‡åˆé©çš„æ©Ÿå™¨å­¸ç¿’æ¨¡å‹
- **ç‰¹å¾µå·¥ç¨‹**ï¼šåˆ©ç”¨ç›¸é—œæ€§åˆ†æçµæœé€²è¡Œç‰¹å¾µé¸æ“‡
- **è³‡æ–™å¢å¼·è©•ä¼°**ï¼šæ¯”è¼ƒåŸå§‹è³‡æ–™å’Œç”Ÿæˆè³‡æ–™çš„åˆ†å¸ƒç‰¹æ€§

## âš™ï¸ ç³»çµ±éœ€æ±‚

### **è»Ÿé«”éœ€æ±‚**
- Python 3.8+
- PyTorch 2.0+
- å…¶ä»–ä¾è³´: pandas, numpy, scikit-learn, matplotlib, seaborn, umap-learn

### **ç¡¬é«”éœ€æ±‚**
- **CPU**: ç¾ä»£å¤šæ ¸å¿ƒè™•ç†å™¨
- **RAM**: å»ºè­° 8GB ä»¥ä¸Š
- **å„²å­˜ç©ºé–“**: 5GB å¯ç”¨ç©ºé–“
- **GPU**: å¯é¸ï¼ŒCUDA æ”¯æ´çš„é¡¯å¡å¯å¤§å¹…åŠ é€Ÿè¨“ç·´

## ğŸ”§ æ•…éšœæ’é™¤

### **è¨“ç·´å•é¡Œ**

#### ğŸ”´ è¨˜æ†¶é«”ä¸è¶³
```bash
# æ¸›å°‘æ‰¹æ¬¡å¤§å°
python train_model.py --batch-size 4

# ä½¿ç”¨è¼ƒå°çš„æ¨¡å‹
python train_model.py --latent-dim 128
```

#### ğŸ”´ è¨“ç·´éæ…¢
```bash
# ä½¿ç”¨GPU (å¦‚æœå¯ç”¨)
python train_model.py --device cuda

# æ¸›å°‘è¨“ç·´é€±æœŸ
python train_model.py --epochs 50
```

### **ç”Ÿæˆå•é¡Œ**

#### ğŸ”´ æ¨¡å‹æª”æ¡ˆéºå¤±
```bash
# å…ˆè¨“ç·´æ¨¡å‹
python train_model.py

# ç„¶å¾Œç”Ÿæˆè³‡æ–™
python generate_data.py --balanced
```

#### ğŸ”´ ç”Ÿæˆå¤±æ•—
ç¢ºä¿ä»¥ä¸‹æª”æ¡ˆå­˜åœ¨ï¼š
- `models/leukemia_cvae_model.pth`
- `datasets/scaler.pkl`
- `datasets/metadata.pkl` (å«åŸºå› åç¨±)

#### ğŸ”´ ğŸ†• åœ–è¡¨ç”Ÿæˆå¤±æ•—
```bash
# è·³éåœ–è¡¨ç”Ÿæˆï¼Œåƒ…ç”Ÿæˆè³‡æ–™
python generate_data.py --balanced --samples-per-class 50 --no-plots

# æª¢æŸ¥æ˜¯å¦å®‰è£äº†è¦–è¦ºåŒ–ä¾è³´
pip install matplotlib seaborn umap-learn
```

### **ğŸ†• åˆ†æå•é¡Œ**

#### ğŸ”´ åˆ†æå·¥å…·è¨˜æ†¶é«”ä¸è¶³
```bash
# æ¸›å°‘ç›¸é—œæ€§åˆ†æçš„ç‰¹å¾µæ•¸é‡
python analyze_dataset.py dataset.csv --max-corr-features 50

# è·³éè¨ˆç®—å¯†é›†çš„åˆ†æ
python analyze_dataset.py dataset.csv --skip-correlation --skip-tsne
```

#### ğŸ”´ UMAP æœªå®‰è£
```bash
# å®‰è£ UMAP (å·²åŒ…å«åœ¨ requirements.txt ä¸­)
pip install umap-learn

# æˆ–è·³é UMAP åˆ†æ
python analyze_dataset.py dataset.csv --skip-umap
```

#### ğŸ”´ è¨ˆç®—æ™‚é–“éé•·
```bash
# t-SNE è‡ªå‹•å°å¤§è³‡æ–™é›†æ¡æ¨£ï¼Œæˆ–å¯æ‰‹å‹•è·³é
python analyze_dataset.py dataset.csv --skip-tsne

# æ¸›å°‘ç›¸é—œæ€§åˆ†æè² æ“”
python analyze_dataset.py dataset.csv --max-corr-features 30
```

#### ğŸ”´ è³‡æ–™æ ¼å¼å•é¡Œ
- **CSV æ ¼å¼**ï¼šå¿…é ˆåŒ…å« `type` æ¬„ä½è¡¨ç¤ºé¡åˆ¥æ¨™ç±¤
- **PKL æ ¼å¼**ï¼šå¿…é ˆåŒ…å« `features`ã€`labels` éµå€¼
- **ç·¨ç¢¼å•é¡Œ**ï¼šç¢ºä¿æª”æ¡ˆä½¿ç”¨ UTF-8 ç·¨ç¢¼

### **ç’°å¢ƒå•é¡Œ**

#### ğŸ”´ ä¾è³´å¥—ä»¶å•é¡Œ
```bash
# å®‰è£å®Œæ•´ä¾è³´
pip install -r requirements.txt

# æˆ–ä½¿ç”¨conda
conda install pytorch pandas numpy scikit-learn matplotlib seaborn
conda install -c conda-forge umap-learn
```

## æ”¯æ´èˆ‡é€²éšä½¿ç”¨

### **å‘½ä»¤åˆ—åƒæ•¸å®Œæ•´åˆ—è¡¨**

#### **è¨“ç·´è…³æœ¬ (train_model.py)**
```bash
--config          # é…ç½®æª”æ¡ˆè·¯å¾‘
--epochs          # è¨“ç·´é€±æœŸæ•¸ (é è¨­: 100)
--batch-size      # æ‰¹æ¬¡å¤§å° (é è¨­: 8)
--learning-rate   # å­¸ç¿’ç‡ (é è¨­: 1e-4)
--latent-dim      # æ½›åœ¨ç©ºé–“ç¶­åº¦ (é è¨­: 256)
--device          # é‹ç®—è£ç½® (é è¨­: auto)
```

#### **ç”Ÿæˆè…³æœ¬ (generate_data.py) ğŸ†•**
```bash
--type               # ç™½è¡€ç—…é¡å‹
--balanced           # ç”Ÿæˆå¹³è¡¡è³‡æ–™é›†
--samples            # æ¨£æœ¬æ•¸é‡ (å–®ä¸€é¡å‹)
--samples-per-class  # æ¯é¡æ¨£æœ¬æ•¸ (å¹³è¡¡è³‡æ–™é›†)
--format             # è¼¸å‡ºæ ¼å¼ (csv/pkl/both)
--output             # è‡ªè¨‚æª”åå‰ç¶´ (é è¨­: generated_data)
--output-dir         # è¼¸å‡ºç›®éŒ„
--no-plots           # ğŸ†• è·³éè¦–è¦ºåŒ–åœ–è¡¨ç”Ÿæˆ
```

#### **ğŸ†• åˆ†æè…³æœ¬ (analyze_dataset.py)**
```bash
python analyze_dataset.py <dataset_path> [é¸é …]

å¿…è¦åƒæ•¸:
  dataset_path              è³‡æ–™é›†æª”æ¡ˆè·¯å¾‘ (.csv æˆ– .pkl)

å¯é¸åƒæ•¸:
  --output-dir DIR          è¼¸å‡ºç›®éŒ„ (é è¨­: datasets/plots)
  --skip-pca               è·³é PCA åˆ†æ
  --skip-tsne              è·³é t-SNE åˆ†æ
  --skip-umap              è·³é UMAP åˆ†æ
  --skip-correlation       è·³éç›¸é—œæ€§åˆ†æ
  --skip-statistics        è·³éçµ±è¨ˆåˆ†æ
  --max-corr-features N    ç›¸é—œæ€§åˆ†ææœ€å¤§ç‰¹å¾µæ•¸ (é è¨­: 100)
```

### **Python API é€²éšåŠŸèƒ½**
```python
# æª¢æŸ¥æ ¼å¼å…¼å®¹æ€§
generator = LeukemiaCVAEGenerator()
print(f"Gene names loaded: {len(generator.gene_names)}")
print(f"First 5 genes: {generator.gene_names[:5]}")

# æ‰¹æ¬¡ç”Ÿæˆå¤šç¨®é¡å‹
for leukemia_type in ['AML', 'PB', 'Bone_Marrow']:
    data = generator.generate_samples(leukemia_type, n_samples=50)
    # è³‡æ–™æ ¼å¼èˆ‡åŸå§‹è³‡æ–™å®Œå…¨ç›¸åŒ
```

### **ğŸ†• å°ˆæ¥­åˆ†æé€²éšç”¨æ³•**
```python
from analyze_dataset import DatasetAnalyzer

# åˆå§‹åŒ–åˆ†æå™¨
analyzer = DatasetAnalyzer(output_base_dir='custom_analysis')

# è‡ªè¨‚åˆ†æåƒæ•¸
analyzer.tsne_params = {'n_components': 2, 'perplexity': 50}
analyzer.umap_params = {'n_neighbors': 30, 'min_dist': 0.1}

# åŸ·è¡Œåˆ†æ
output_dir = analyzer.analyze_dataset(
    'datasets/my_data.csv',
    include_umap=True,
    max_correlation_features=200
)
```