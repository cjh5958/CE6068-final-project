import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.preprocessing import StandardScaler, LabelEncoder
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from catboost import CatBoostClassifier

# è¼‰å…¥å…©ä»½è³‡æ–™
df1 = pd.read_csv("datasets/raw_data.csv")
df2 = pd.read_csv("datasets/generated_data.csv")

# å‰è™•ç†ï¼ˆå‡è¨­æ ¼å¼ç›¸åŒï¼‰
df1 = df1.drop(columns=["samples"])
df2 = df2.drop(columns=["samples"])

# ç§»é™¤ç¼ºå¤±å€¼
df1 = df1.dropna()
df2 = df2.dropna()

# æ‹†é–‹ X å’Œ y
X1 = df1.drop(columns=['type'])
y1 = df1['type']

X2 = df2.drop(columns=['type'])
y2 = df2['type']

# å° y åš label encodingï¼ˆä½¿ç”¨åŒä¸€å€‹ encoder ç¢ºä¿ä¸€è‡´æ€§ï¼‰
le = LabelEncoder()
y1_encoded = le.fit_transform(y1)
y2_encoded = le.transform(y2)  # æ³¨æ„ï¼šå‡è¨­ df2 è£¡çš„ type æ²’æœ‰æ–°é¡åˆ¥ï¼

# ç”¨ data1 åˆ‡ train/test
X1_train, X1_test, y1_train, y1_test = train_test_split(
    X1, y1_encoded, test_size=0.5, stratify=y1_encoded, random_state=42
)

# æŠŠ data2 åŠ é€² train
X_train = pd.concat([pd.DataFrame(X1_train), pd.DataFrame(X2)], ignore_index=True)
y_train = pd.concat([pd.Series(y1_train), pd.Series(y2_encoded)], ignore_index=True)

# æ¸¬è©¦è³‡æ–™ä»ç„¶åªç”¨ data1 çš„ä¸€åŠ
X_test = X1_test
y_test = y1_test


# æ¨¡å‹å®šç¾©
base_models = {
    "Logistic Regression": LogisticRegression(max_iter=1000, random_state=42),
    "KNN": KNeighborsClassifier(),
    "Decision Tree": DecisionTreeClassifier(random_state=42),
    #"Gradient Boosting": GradientBoostingClassifier(random_state=42),
    "MLP": MLPClassifier(random_state=42),
    "Random Forest": RandomForestClassifier(random_state=42),
    #"XGBoost": XGBClassifier(eval_metric='logloss', random_state=42),
    #"LightGBM": LGBMClassifier(random_state=42,force_col_wise=True,),
    #"CatBoost": CatBoostClassifier(verbose=0, random_state=42),
}

"""# åŠ å…¥ Stacking æ¨¡å‹
stacking_model = StackingClassifier(
    estimators=[
        ('rf', base_models["Random Forest"]),
        ('gb', base_models["Gradient Boosting"]),
        ('knn', base_models["KNN"])
    ],
    final_estimator=LogisticRegression(),
    cv=5
)
base_models["Stacking"] = stacking_model"""

# æ¨™æº–åŒ–
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
models_need_scaling = ["KNN", "MLP", "Logistic Regression", "SVC"]

# é–‹å•Ÿè¼¸å‡ºæª”æ¡ˆ
output_path = "model_results.txt"
with open(output_path, "w", encoding="utf-8") as f:
    for model_name, model in base_models.items():
        print(f"\nğŸ”§ Training {model_name}...")
        f.write(f"\nğŸ”§ Training {model_name}...\n")

        if model_name in models_need_scaling:
            model.fit(X_train_scaled, y_train)
            y_pred = model.predict(X_test_scaled)
        else:
            model.fit(X_train, y_train)
            y_pred = model.predict(X_test)

        y_test_labels = le.inverse_transform(y_test)
        y_pred_labels = le.inverse_transform(y_pred)

        # æ··æ·†çŸ©é™£èˆ‡å ±å‘Š
        cm = confusion_matrix(y_test_labels, y_pred_labels)
        cr = classification_report(y_test_labels, y_pred_labels)
        acc = accuracy_score(y_test_labels, y_pred_labels)

        # å°å‡ºèˆ‡å¯«å…¥æª”æ¡ˆ
        print(f"{model_name} Confusion Matrix:")
        print(cm)
        print(f"{model_name} Classification Report:")
        print(cr)
        print(f"{model_name} Accuracy: {acc:.4f}")
        print("-" * 60)

        f.write(f"{model_name} Confusion Matrix:\n{cm}\n")
        f.write(f"{model_name} Classification Report:\n{cr}\n")
        f.write(f"{model_name} Accuracy: {acc:.4f}\n")
        f.write("-" * 60 + "\n")

print(f"\nâœ… æ‰€æœ‰æ¨¡å‹çµæœå·²å„²å­˜è‡³ï¼š{output_path}")